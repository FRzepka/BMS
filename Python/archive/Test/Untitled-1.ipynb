{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Anzahl GPUs: 1\n",
      "GPU 0: NVIDIA A30\n",
      "Ergebnis-Tensor z (shape=torch.Size([1000, 1000])) liegt auf Gerät: cuda:0\n",
      "Mean of z: 250.00181579589844\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1) Zeige an, ob CUDA verfügbar ist.\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "# 2) Falls verfügbar, gib zusätzliche Infos aus:\n",
    "if cuda_available:\n",
    "    print(f\"Anzahl GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# 3) Führe einen kleinen Test durch: \n",
    "#    - Erstelle einen Tensor auf der GPU, falls verfügbar.\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "x = torch.rand((1000, 1000), device=device)\n",
    "y = torch.rand((1000, 1000), device=device)\n",
    "\n",
    "# 4) Mache eine Matrixmultiplikation und gib das Ergebnis (oder einen Ausschnitt) aus.\n",
    "z = torch.matmul(x, y)\n",
    "print(f\"Ergebnis-Tensor z (shape={z.shape}) liegt auf Gerät: {z.device}\")\n",
    "\n",
    "# 5) Optional: Drucke einen kleinen Teil des Tensors (z.B. Mittelwert)\n",
    "print(f\"Mean of z: {z.mean().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -c \"import torch; print(torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUDA-Prüfung mit PyTorch ===\n",
      "PyTorch Version: 2.5.1+cu118\n",
      "CUDA ist verfügbar!\n",
      "Anzahl CUDA-Geräte: 1\n",
      "Gerät 0: NVIDIA A30\n",
      "\n",
      "=== Überprüfe Package-Importe und Versionsnummern ===\n",
      "Python Version: 3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:51:40) \n",
      "[GCC 13.3.0]\n",
      "torch Version: 2.5.1+cu118\n",
      "lightning.pytorch Version: 2.5.0.post0\n",
      "numpy Version: 1.26.3\n",
      "pandas Version: 2.2.3\n",
      "matplotlib Version: 3.9.4\n",
      "pytorch_forecasting Version: 1.2.0\n",
      "darts Version: 0.32.0\n",
      "sklearn Version: 1.5.2\n",
      "\n",
      "=== Überprüfe das custom Modul 'battery_script' ===\n",
      "battery_script wurde erfolgreich importiert.\n",
      "battery_script Version: Keine __version__-Angabe\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Dieses Skript überprüft, ob CUDA verfügbar ist und ob alle benötigten Packages\n",
    "korrekt importiert werden können. Zudem werden die Versionsnummern der Module ausgegeben.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import importlib\n",
    "\n",
    "def check_cuda():\n",
    "    print(\"=== CUDA-Prüfung mit PyTorch ===\")\n",
    "    try:\n",
    "        import torch\n",
    "        print(\"PyTorch Version:\", torch.__version__)\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"CUDA ist verfügbar!\")\n",
    "            device_count = torch.cuda.device_count()\n",
    "            print(\"Anzahl CUDA-Geräte:\", device_count)\n",
    "            for i in range(device_count):\n",
    "                print(f\"Gerät {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        else:\n",
    "            print(\"CUDA ist NICHT verfügbar.\")\n",
    "    except Exception as e:\n",
    "        print(\"Fehler beim Importieren von PyTorch oder bei der CUDA-Prüfung:\", e)\n",
    "\n",
    "def check_package_versions():\n",
    "    print(\"\\n=== Überprüfe Package-Importe und Versionsnummern ===\")\n",
    "    \n",
    "    # Hier werden die Packages definiert, die geprüft werden sollen.\n",
    "    packages = {\n",
    "        \"Python\": None,  # Python-Version wird separat behandelt\n",
    "        \"torch\": \"torch\",\n",
    "        \"lightning.pytorch\": \"lightning.pytorch\",\n",
    "        \"numpy\": \"numpy\",\n",
    "        \"pandas\": \"pandas\",\n",
    "        \"matplotlib\": \"matplotlib\",\n",
    "        \"pytorch_forecasting\": \"pytorch_forecasting\",\n",
    "        \"darts\": \"darts\",\n",
    "        \"sklearn\": \"sklearn\",\n",
    "        # Weitere Packages können hier ergänzt werden, falls nötig.\n",
    "    }\n",
    "    \n",
    "    # Ausgabe der Python-Version\n",
    "    print(\"Python Version:\", sys.version)\n",
    "    \n",
    "    for pkg_name, module_name in packages.items():\n",
    "        if module_name is None:\n",
    "            continue  # Überspringe, falls keine Modulzuordnung vorhanden ist\n",
    "        try:\n",
    "            module = importlib.import_module(module_name)\n",
    "            version = getattr(module, '__version__', 'Keine __version__-Angabe')\n",
    "            print(f\"{pkg_name} Version: {version}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Importieren von {pkg_name} ({module_name}): {e}\")\n",
    "    \n",
    "    # Prüfe zusätzlich das custom Modul 'battery_script'\n",
    "    print(\"\\n=== Überprüfe das custom Modul 'battery_script' ===\")\n",
    "    try:\n",
    "        import battery_script\n",
    "        version = getattr(battery_script, '__version__', 'Keine __version__-Angabe')\n",
    "        print(\"battery_script wurde erfolgreich importiert.\")\n",
    "        print(\"battery_script Version:\", version)\n",
    "    except Exception as e:\n",
    "        print(\"Fehler beim Importieren von battery_script:\", e)\n",
    "\n",
    "def main():\n",
    "    # Optionale Logging- und Warnungskonfiguration\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    check_cuda()\n",
    "    check_package_versions()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # Sollte eine CUDA-Version (z.B. \"11.8\") ausgeben, wenn CUDA unterstützt wird\n",
    "print(torch.cuda.is_available())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
